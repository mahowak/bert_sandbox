{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "big\n",
      "beautiful\n",
      "market\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"UCSB is a [MASK] place.\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "maskedlm = input_ids.clone().detach()\n",
    "\n",
    "outputs = model(input_ids) #, masked_lm_labels=maskedlm)\n",
    "\n",
    "prediction_scores = outputs.logits\n",
    "\n",
    "mask = [int(i) for i in maskedlm[0]].index(103)\n",
    "\n",
    "args = prediction_scores[0][mask].topk(5)[1]\n",
    "for i in args:\n",
    "    print(tokenizer.decode([int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_prob(sent):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor(tokenizer.encode(sent, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        maskedlm = input_ids.clone().detach()\n",
    "        scores = []\n",
    "        masks = [i for i in range(len(input_ids[0])) if int(input_ids[0][i]) == tokenizer.mask_token_id]\n",
    "        for mask in masks:\n",
    "            outputs = model(maskedlm) \n",
    "            prediction_scores = outputs.logits\n",
    "            pscores = torch.log(torch.softmax(prediction_scores[0], 1))\n",
    "            probs, args = pscores[mask].topk(20)\n",
    "            results += [([tokenizer.decode([int(a)]) for a in args], [round(float(p), 3) for p in probs])]\n",
    "            maskedlm = input_ids.clone().detach()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_prob(sent, word_list):\n",
    "    results = []\n",
    "    word_list_ids = tokenizer.encode(word_list)\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor(tokenizer.encode(sent, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        maskedlm = input_ids.clone().detach()\n",
    "        scores = []\n",
    "        masks = [i for i in range(len(input_ids[0])) if int(input_ids[0][i]) == tokenizer.mask_token_id]\n",
    "        for mask in masks:\n",
    "            outputs = model(maskedlm) #, masked_lm_labels=maskedlm)\n",
    "            prediction_scores = outputs.logits\n",
    "            pscores = torch.log(torch.softmax(prediction_scores[0], 1))\n",
    "            for word in word_list_ids:\n",
    "                results += [(tokenizer.decode([word]), pscores[mask][word])]\n",
    "            maskedlm = input_ids.clone().detach()\n",
    "    print(sent)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['reading', 'knowing', 'writing', 'answering', 'asking', 'listening', 'trying', 'looking', 'publishing', 'learning', 'starting', 'seeing', 'finishing', 'checking', 'talking', 'speaking', 'studying', 'participating', 'stopping', 'going'], [-0.768, -2.47, -3.133, -3.242, -3.811, -3.958, -3.979, -4.034, -4.097, -4.584, -4.585, -4.689, -4.874, -4.948, -5.018, -5.036, -5.045, -5.079, -5.095, -5.157])]\n",
      "[(['reading', 'knowing', 'speaking', 'listening', 'looking', 'asking', 'answering', 'talking', 'participating', 'commenting', 'seeing', 'trying', 'voting', 'going', 'visiting', 'writing', 'thinking', 'checking', 'attending', 'saying'], [-2.041, -2.16, -2.643, -2.751, -2.889, -3.015, -3.214, -3.473, -3.783, -4.18, -4.204, -4.23, -4.264, -4.397, -4.416, -4.416, -4.444, -4.706, -4.708, -4.831])]\n"
     ]
    }
   ],
   "source": [
    "# try parasitic gaps\n",
    "print(get_mask_prob(\"What book did you review without actually [MASK]?\"))\n",
    "print(get_mask_prob(\"You reviewed that book without actually [MASK].\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['days', 'hours', 'minutes', 'weeks', 'seconds', 'years', 'episodes', 'nights', '##th', 'months', 'hour', '##k', 'min', 'day', 'minute', 'episode', 'birthday', 'night', 'week', 'moments'], [-0.58, -1.436, -2.139, -4.202, -4.239, -4.632, -5.167, -5.246, -5.366, -5.89, -5.978, -6.118, -6.119, -6.321, -6.441, -6.804, -7.401, -7.723, -7.776, -7.836])]\n",
      "[(['weeks', 'days', 'hours', 'years', 'months', 'nights', 'minutes', 'seasons', 'week', 'episodes', 'weekends', 'evenings', 'day', 'hour', 'night', 'summers', 'sundays', 'saturdays', 'decades', 'month'], [-0.964, -1.541, -1.968, -2.539, -2.594, -3.429, -4.288, -4.508, -4.835, -4.927, -5.275, -6.041, -6.113, -6.169, -6.179, -6.278, -6.912, -6.941, -7.007, -7.143])]\n"
     ]
    }
   ],
   "source": [
    "print(get_mask_prob(\"The host spent a special 77 [MASK] on the show.\"))\n",
    "print(get_mask_prob(\"The host spent a special two [MASK] on the show.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['a', 'two', 'three', 'four', 'five', 'some', 'the', 'six', 'several', 'his', 'seven', 'her', 'eight', 'many', 'very', 'these', 'nine', '4', 'one', '5'], [-1.694, -2.0, -2.345, -2.437, -2.747, -2.972, -3.071, -3.28, -3.503, -3.558, -3.667, -3.948, -4.28, -4.359, -4.366, -4.4, -5.001, -5.003, -5.119, -5.199])]\n"
     ]
    }
   ],
   "source": [
    "print(get_mask_prob(\"The student spent [MASK] beautiful five days in Canberra.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will spend a beautiful five [MASK] in Canberra.\n",
      "[('[CLS]', tensor(-21.6975)), ('day', tensor(-8.7000)), ('days', tensor(-0.9306)), ('[SEP]', tensor(-21.0437))]\n",
      "We will spend a beautiful 2818 [MASK] in Canberra.\n",
      "[('[CLS]', tensor(-17.2315)), ('day', tensor(-3.1602)), ('days', tensor(-1.3575)), ('[SEP]', tensor(-15.6093))]\n",
      "The prize went to a lucky three [MASK].\n",
      "[('[CLS]', tensor(-19.2531)), ('player', tensor(-3.5122)), ('players', tensor(-1.9555)), ('[SEP]', tensor(-16.6073))]\n",
      "The prize went to a lucky seventy-four [MASK].\n",
      "[('[CLS]', tensor(-17.1052)), ('player', tensor(-4.6879)), ('players', tensor(-6.3033)), ('[SEP]', tensor(-15.0824))]\n",
      "The prize went to an embarrassed three [MASK].\n",
      "[('[CLS]', tensor(-16.5591)), ('player', tensor(-8.5510)), ('players', tensor(-5.8898)), ('[SEP]', tensor(-15.6126))]\n",
      "The prize went to an embarrassed seventy-four [MASK].\n",
      "[('[CLS]', tensor(-17.3437)), ('player', tensor(-8.1305)), ('players', tensor(-5.5902)), ('[SEP]', tensor(-15.5876))]\n",
      "All credit goes to a special three [MASK].\n",
      "[('[CLS]', tensor(-15.2399)), ('player', tensor(-2.2767)), ('players', tensor(-2.9895)), ('[SEP]', tensor(-15.4344))]\n",
      "All credit goes to a special seventy-four [MASK].\n",
      "[('[CLS]', tensor(-14.2622)), ('player', tensor(-4.0852)), ('players', tensor(-4.9869)), ('[SEP]', tensor(-15.4823))]\n",
      "I have had a busy three [MASK].\n",
      "[('[CLS]', tensor(-19.9256)), ('week', tensor(-8.5474)), ('weeks', tensor(-2.6158)), ('[SEP]', tensor(-19.1451))]\n",
      "I have had a busy seventy-seven [MASK].\n",
      "[('[CLS]', tensor(-18.2679)), ('week', tensor(-11.3698)), ('weeks', tensor(-5.3830)), ('[SEP]', tensor(-18.3221))]\n",
      "We walked a wintry seventy-two [MASK].\n",
      "[('[CLS]', tensor(-20.0885)), ('block', tensor(-8.8205)), ('blocks', tensor(-4.5099)), ('[SEP]', tensor(-19.8886))]\n",
      "We walked a wintry three [MASK].\n",
      "[('[CLS]', tensor(-21.3609)), ('block', tensor(-8.3488)), ('blocks', tensor(-2.4171)), ('[SEP]', tensor(-19.3660))]\n",
      "We walked a wintry seventy-two [MASK].\n",
      "[('[CLS]', tensor(-20.0885)), ('block', tensor(-8.8205)), ('blocks', tensor(-4.5099)), ('[SEP]', tensor(-19.8886))]\n",
      "We walked a wintry three [MASK].\n",
      "[('[CLS]', tensor(-21.3609)), ('block', tensor(-8.3488)), ('blocks', tensor(-2.4171)), ('[SEP]', tensor(-19.3660))]\n",
      "The host spent a special ten [MASK] on the show.\n",
      "[('[CLS]', tensor(-19.5354)), ('night', tensor(-7.5462)), ('nights', tensor(-6.2183)), ('[SEP]', tensor(-17.5784))]\n",
      "The host spent a special two [MASK] on the show.\n",
      "[('[CLS]', tensor(-20.0505)), ('night', tensor(-6.1791)), ('nights', tensor(-3.4292)), ('segment', tensor(-11.3408)), ('segments', tensor(-9.8159)), ('[SEP]', tensor(-18.9903))]\n",
      "The host spent a special 1212 [MASK] on the show.\n",
      "[('[CLS]', tensor(-21.1779)), ('night', tensor(-7.6055)), ('nights', tensor(-4.2674)), ('segment', tensor(-15.2989)), ('segments', tensor(-14.5100)), ('[SEP]', tensor(-19.5339))]\n"
     ]
    }
   ],
   "source": [
    "print(get_word_prob(\"We will spend a beautiful five [MASK] in Canberra.\", [\"day\", \"days\"]))\n",
    "print(get_word_prob(\"We will spend a beautiful 2818 [MASK] in Canberra.\", [\"day\", \"days\"]))\n",
    "print(get_word_prob(\"The prize went to a lucky three [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"The prize went to a lucky seventy-four [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"The prize went to an embarrassed three [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"The prize went to an embarrassed seventy-four [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"All credit goes to a special three [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"All credit goes to a special seventy-four [MASK].\", [\"player\", \"players\"]))\n",
    "print(get_word_prob(\"I have had a busy three [MASK].\", [\"week\", \"weeks\"]))\n",
    "print(get_word_prob(\"I have had a busy seventy-seven [MASK].\", [\"week\", \"weeks\"]))\n",
    "print(get_word_prob(\"We walked a wintry seventy-two [MASK].\", [\"block\", \"blocks\"]))\n",
    "print(get_word_prob(\"We walked a wintry three [MASK].\", [\"block\", \"blocks\"]))\n",
    "print(get_word_prob(\"We walked a wintry seventy-two [MASK].\", [\"block\", \"blocks\"]))\n",
    "print(get_word_prob(\"We walked a wintry three [MASK].\", [\"block\", \"blocks\"]))\n",
    "print(get_word_prob(\"The host spent a special ten [MASK] on the show.\", [\"night\", \"nights\"]))\n",
    "print(get_word_prob(\"The host spent a special two [MASK] on the show.\", [\"night\", \"nights\", \"segment\", \"segments\"]))\n",
    "print(get_word_prob(\"The host spent a special 1212 [MASK] on the show.\", [\"night\", \"nights\", \"segment\", \"segments\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I reviewed a remarkable four [MASK].\n",
      "[('[CLS]', tensor(-14.2232)), ('paper', tensor(-8.7153)), ('papers', tensor(-3.7857)), ('[SEP]', tensor(-15.4789))]\n",
      "I reviewed a remarkable seventy-four [MASK].\n",
      "[('[CLS]', tensor(-14.7811)), ('paper', tensor(-7.9636)), ('papers', tensor(-3.1446)), ('[SEP]', tensor(-16.2712))]\n",
      "We spent a beautiful eighty [MASK] in Canberra.\n",
      "[('[CLS]', tensor(-19.1133)), ('day', tensor(-6.8273)), ('days', tensor(-0.4375)), ('[SEP]', tensor(-18.3835))]\n"
     ]
    }
   ],
   "source": [
    "print(get_word_prob(\"I reviewed a remarkable four [MASK].\", [\"paper\", \"papers\"]))\n",
    "print(get_word_prob(\"I reviewed a remarkable seventy-four [MASK].\", [\"paper\", \"papers\"]))\n",
    "print(get_word_prob(\"We spent a beautiful eighty [MASK] in Canberra.\", [\"day\", \"days\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I met a [MASK] five people yesterday.\n",
      "[('[CLS]', tensor(-16.6099)), ('special', tensor(-9.9151)), ('lucky', tensor(-5.9449)), ('handsome', tensor(-8.0705)), ('tall', tensor(-8.4602)), ('[SEP]', tensor(-17.2869))]\n",
      "I met a [MASK] seventy-seven people yesterday.\n",
      "[('[CLS]', tensor(-15.2442)), ('special', tensor(-11.0371)), ('lucky', tensor(-8.5766)), ('handsome', tensor(-8.7123)), ('tall', tensor(-10.9221)), ('[SEP]', tensor(-16.8270))]\n"
     ]
    }
   ],
   "source": [
    "print(get_word_prob(\"I met a [MASK] five people yesterday.\", [\"special\", \"lucky\", \"handsome\", \"tall\"]))\n",
    "print(get_word_prob(\"I met a [MASK] seventy-seven people yesterday.\", [\"special\", \"lucky\", \"handsome\", \"tall\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['few', 'two', 'three', 'five', 'four', 'many', 'six', 'seven', 'dozen', 'couple', 'ten', 'eight', 'hundred', '10', 'nine', 'thousand', 'twenty', 'twelve', 'eleven', 'fifty'], [-0.289, -3.087, -3.206, -3.948, -4.047, -4.18, -4.3, -4.307, -4.503, -4.561, -4.57, -5.074, -5.196, -5.839, -5.984, -6.29, -6.293, -6.474, -6.627, -6.638])]\n",
      "[(['two', 'three', 'few', 'poor', 'young', 'rich', 'four', 'white', 'five', 'other', 'seven', 'six', 'little', 'black', 'good', 'eight', 'day', 'nice', 'ten', 'new'], [-1.974, -2.625, -2.665, -2.714, -3.312, -3.313, -3.421, -3.499, -3.656, -3.687, -3.783, -3.814, -3.835, -3.913, -3.939, -4.335, -4.483, -4.533, -4.676, -4.824])]\n",
      "[(['players', 'contestants', 'teams', 'winners', 'losers', 'contestant', 'player', 'people', 'team', 'men', 'competitors', 'women', 'horses', 'couples', 'participants', 'winner', 'finalists', 'votes', 'members', 'entries'], [-1.956, -2.105, -2.387, -3.059, -3.438, -3.44, -3.512, -3.554, -3.933, -3.971, -4.291, -4.374, -4.465, -4.527, -4.576, -4.585, -5.028, -5.032, -5.048, -5.125])]\n",
      "[(['days', 'trains', 'train', 'columns', '##s', 'flags', 'wheeler', 'horses', 'column', 'seater', 'teams', 'cars', 'hours', 'carriages', 'trucks', 'men', 'horse', 'vehicles', 'car', 'stars'], [-2.996, -3.344, -3.753, -3.865, -3.905, -3.939, -4.027, -4.182, -4.317, -4.32, -4.337, -4.346, -4.352, -4.589, -4.611, -4.703, -4.905, -4.958, -4.967, -4.974])]\n",
      "[(['few', 'three', 'two', 'couple', 'four', 'seven', 'five', 'ten', 'six', 'eight', 'many', 'nine', 'several', 'hundred', '30', 'fourteen', '25', '3', 'sixteen', 'twenty'], [-0.46, -2.437, -2.574, -3.308, -3.42, -3.953, -3.961, -4.377, -4.515, -5.379, -5.406, -5.545, -5.615, -6.018, -6.13, -6.137, -6.207, -6.244, -6.318, -6.355])]\n",
      "[(['summer', 'winter', 'spring', 'sunny', 'early', 'wedding', 'school', 'christmas', 'autumn', 'three', 'long', 'first', 'new', 'saturday', 'rainy', 'hot', 'vacation', 'two', 'sunday', 'happy'], [-0.303, -3.518, -3.713, -3.877, -4.854, -4.938, -5.062, -5.074, -5.181, -5.228, -5.276, -5.319, -5.501, -5.514, -5.557, -5.592, -5.613, -5.731, -5.741, -5.854])]\n",
      "[(['good', 'full', 'whole', 'further', 'solid', 'total', 'combined', 'mere', 'long', 'record', 'hard', 'great', 'rough', 'big', 'fantastic', 'nice', 'tough', 'decent', 'flat', 'pleasant'], [-1.171, -1.432, -2.231, -2.539, -2.596, -4.268, -4.581, -4.62, -4.704, -4.725, -4.889, -4.923, -5.094, -5.27, -5.275, -5.332, -5.468, -5.831, -6.496, -6.508])]\n",
      "[(['good', 'whole', 'big', 'record', 'nice', 'further', 'total', 'full', 'couple', 'fantastic', '...', 'great', 'mere', 'few', 'little', 'solid', 'friend', 'hundred', 'maybe', 'figure'], [-0.758, -2.681, -3.055, -3.148, -3.178, -3.42, -3.745, -3.78, -3.945, -4.078, -4.092, -4.429, -5.069, -5.386, -5.459, -5.555, -5.56, -5.579, -5.586, -5.694])]\n",
      "[(['further', 'maximum', 'top', 'final', 'total', 'minimum', 'first', 'record', 'combined', 'possible', 'full', 'mere', 'best', 'remaining', 'prize', 'good', 'last', 'bottom', 'next', 'additional'], [-0.815, -1.65, -1.86, -3.033, -3.521, -3.888, -4.168, -4.283, -4.784, -5.008, -5.03, -5.28, -5.633, -5.74, -5.858, -6.538, -6.568, -6.586, -6.696, -7.069])]\n"
     ]
    }
   ],
   "source": [
    "print(get_mask_prob(\"I met a lucky [MASK] people yesterday.\"))\n",
    "print(get_mask_prob(\"I met lucky [MASK] people yesterday.\"))\n",
    "print(get_mask_prob(\"The prize went to a lucky three [MASK].\"))\n",
    "print(get_mask_prob(\"The day was carried by a special three [MASK].\"))\n",
    "print(get_mask_prob(\"We spent a beautiful [MASK] days in Canberra.\"))\n",
    "print(get_mask_prob(\"We spent beautiful [MASK] days in Canberra.\"))\n",
    "print(get_mask_prob(\"We spent a [MASK] four days in Canberra.\"))\n",
    "print(get_mask_prob(\"I met a [MASK] five people yesterday.\"))\n",
    "print(get_mask_prob(\"The prize went to a [MASK] three players.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['player', 'winner', 'contestant', 'team', 'person', '##er', 'loser', 'participant', 'ticket', 'players', 'contestants', 'winners', 'horse', 'driver', 'prize', 'losers', 'candidate', 'member', 'survivor', 'entry'], [-1.363, -1.938, -2.015, -2.89, -3.538, -3.838, -3.93, -4.252, -4.313, -4.878, -4.9, -4.927, -5.115, -5.148, -5.154, -5.158, -5.329, -5.329, -5.371, -5.419])]\n",
      "[(['couple', 'family', 'ending', 'loser', 'person', 'man', 'birthday', 'child', 'woman', 'girl', 'wife', 'widow', 'husband', 'one', 'boy', 'friend', 'marriage', 'heart', 'survivor', 'killer'], [-1.33, -1.882, -3.269, -3.382, -3.554, -4.122, -4.458, -4.465, -4.698, -4.79, -4.869, -4.898, -4.926, -4.992, -5.266, -5.332, -5.406, -5.425, -5.432, -5.482])]\n"
     ]
    }
   ],
   "source": [
    "print(get_mask_prob(\"The prize went to a lucky ten [MASK].\"))\n",
    "print(get_mask_prob(\"The prize went to a lucky happy [MASK].\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['guineas', 'dollars', 'pounds', 'points', 'hundred', 'thousand', 'people', 'million', 'men', 'cents', 'shillings', 'players', 'bucks', 'winners', 'horses', 'times', 'tickets', 'stars', 'votes', 'women'], [-1.934, -2.048, -2.362, -2.366, -3.102, -3.185, -3.584, -3.699, -3.957, -4.094, -4.825, -4.95, -4.965, -5.033, -5.142, -5.226, -5.423, -5.424, -5.426, -5.431])]\n",
      "[(['pounds', 'dollars', 'guineas', 'men', 'points', 'people', 'cents', 'thousand', 'bucks', 'souls', 'hundred', 'votes', 'dragons', 'heads', 'spectators', 'lives', 'horses', 'percent', 'million', 'warriors'], [-1.1, -1.101, -3.392, -3.829, -4.029, -4.047, -4.05, -4.441, -4.473, -4.567, -5.708, -5.739, -5.825, -5.854, -5.938, -5.951, -6.02, -6.075, -6.076, -6.133])]\n",
      "[(['guy', 'man', 'boy', 'girl', 'dog', 'brother', 'one', 'cat', 'bear', 'boss', 'wolf', '##foot', 'thing', 'bull', 'kid', 'bitch', 'dick', 'woman', 'sister', 'rat'], [-1.879, -2.184, -2.938, -3.461, -3.477, -3.559, -3.674, -3.856, -4.035, -4.286, -4.582, -4.643, -5.132, -5.183, -5.298, -5.307, -5.368, -5.412, -5.477, -5.511])]\n"
     ]
    }
   ],
   "source": [
    "print(get_mask_prob(\"The prize went to a whopping three [MASK].\"))\n",
    "print(get_mask_prob(\"The prize went to a whopping seventy-two [MASK].\"))\n",
    "print(get_mask_prob(\"The prize went to a whopping big [MASK].\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.3999,  -6.3635,  -6.3764,  ...,  -5.8375,  -5.5929,  -3.8700],\n",
       "         [ -7.0323,  -7.3702,  -6.8279,  ...,  -7.1544,  -5.1179,  -3.5200],\n",
       "         [ -8.4059,  -8.1868,  -7.9537,  ...,  -6.6552,  -3.6863,  -8.2279],\n",
       "         ...,\n",
       "         [ -9.8070,  -9.9536,  -9.6722,  ...,  -8.9193,  -8.3495,  -9.8221],\n",
       "         [-12.6997, -12.4316, -12.9278,  ..., -11.2620, -10.5817,  -6.6558],\n",
       "         [-10.2625, -10.2069, -10.2232,  ...,  -9.7631,  -9.0680,  -6.1355]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model internals\n",
    "input_ids = torch.tensor(tokenizer.encode(\"The dog chased the cat.\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "maskedlm = input_ids.clone().detach()\n",
    "\n",
    "outputs = model(input_ids,output_hidden_states=True) #, masked_lm_labels=maskedlm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13 layers\n",
    "len(outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 word vectors, each of length 768\n",
    "outputs.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
